% Generated by roxygen2 (4.1.1): do not edit by hand
% Please edit documentation in R/findCNVs.R
\name{findCNVs}
\alias{findCNVs}
\title{Find copy number variations}
\usage{
findCNVs(binned.data, ID, method = "univariate", eps = 0.001,
  init = "standard", max.time = -1, max.iter = -1, num.trials = 10,
  eps.try = 10 * eps, num.threads = 1, read.cutoff.quantile = 0.999,
  GC.correction = TRUE, strand = "*")
}
\arguments{
\item{binned.data}{A \link{GRanges} object with binned read counts.}

\item{ID}{An identifier that will be used to identify this sample in various downstream functions. Could be the file name of the \code{binned.data} for example.}

\item{method}{One of \code{c('univariate','bivariate')}.}

\item{eps}{Convergence threshold for the Baum-Welch algorithm.}

\item{init}{One of the following initialization procedures:
\describe{
    \item{\code{standard}}{The negative binomial of state 'disomy' will be initialized with \code{mean=mean(reads)}, \code{var=var(reads)}. This procedure usually gives good convergence.}
    \item{\code{random}}{Mean and variance of the negative binomial of state 'disomy' will be initialized with random values (in certain boundaries, see source code). Try this if the \code{standard} procedure fails to produce a good fit.}
}}

\item{max.time}{The maximum running time in seconds for the Baum-Welch algorithm. If this time is reached, the Baum-Welch will terminate after the current iteration finishes. The default -1 is no limit.}

\item{max.iter}{The maximum number of iterations for the Baum-Welch algorithm. The default -1 is no limit.}

\item{num.trials}{The number of trials to find a fit where state 'disomic' is most frequent. Each time, the HMM is seeded with different random initial values.}

\item{eps.try}{If code num.trials is set to greater than 1, \code{eps.try} is used for the trial runs. If unset, \code{eps} is used.}

\item{num.threads}{Number of threads to use. Setting this to >1 may give increased performance.}

\item{read.cutoff.quantile}{A quantile between 0 and 1. Should be near 1. Read counts above this quantile will be set to the read count specified by this quantile. Filtering very high read counts increases the performance of the Baum-Welch fitting procedure. However, if your data contains very few peaks they might be filtered out. Set \code{read.cutoff.quantile=1} in this case.}

\item{GC.correction}{Either \code{TRUE} or \code{FALSE}. If \code{GC.correction=TRUE}, the GC corrected reads have to be present in the input \code{binned.data}, otherwise a warning is thrown and no GC correction is done.}

\item{strand}{Run the HMM only for the specified strand. One of \code{c('+', '-', '*')}.}
}
\description{
\code{findCNVs} classifies the binned read counts into several states which represent copy-number-variation.
}
\details{
\code{findCNVs} uses a 6-state Hidden Markov Model to classify the binned read counts: state 'nullsomy' with a delta function as emission densitiy (only zero read counts), 'monosomy','disomy','trisomy','tetrasomy' and 'multisomy' with negative binomials (see \code{\link{dnbinom}}) as emission densities. A Baum-Welch algorithm is employed to estimate the parameters of the distributions. See our paper for a detailed description of the method. TODO: insert paper
}
\examples{
## Get an example BAM file with single-cell-sequencing reads
bamfile <- system.file("extdata/BB140820_I_002.bam", package="aneufinder")
## Bin the BAM file into bin size 200000bp
binned.data <- bam2binned(bamfile, binsize=200000, chromosomes=c(1:22,'X','Y'), GC.correction=FALSE,
                         save.as.RData=FALSE)
## Fit the Hidden Markov Model
model <- findCNVs(binned.data, ID=basename(bamfile), eps=0.1, max.time=60)
## Check the fit
plot(model, type='histogram')
}
\author{
Aaron Taudt
}

